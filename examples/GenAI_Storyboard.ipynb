{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# üé¨‚ú® Generate Automated Video Outputs with Text Prompts | DALL-E + ElevenLabs + OpenAI + VideoDB"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a href=\"https://colab.research.google.com/github/video-db/videodb-cookbook/blob/main/examples/GenAI_Storyboard.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üí¨ Overview\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Generative AI apps and tools are on the rise, but most of them are still focused on automating singular chunk of a workflow- which may be rather time-consuming to put together later on. The biggest blocker in video content generation is the tight duration constraint (owing to token limits & loads). But here‚Äôs a clever solution to remove these blockers and keep your creativity flowing.\n",
    "\n",
    "VideoDB is here to serve as a platform that can bring multiple generative AI outputs together using it‚Äôs multimodal capabilities. This tutorial demonstrates how VideoDB can enable the creation of new-age, generative AI apps/ tools using multimodal inputs and outputs by showcasing a 'storyboarding' tool as an example. \n",
    "\n",
    "Crafting engaging video storyboards for app user flows is often laborious, requiring manual creation of assets like images and voiceovers. However, with VideoDB's powerful integration with AI models like DALL-E, OpenAI, and Eleven Labs, you can automate this process entirely through a simple tool.\n",
    "\n",
    "For this demo storyboarding tool, we would require just 2 simple text inputs from the user (app name and description, and the steps in their user flow). Based on this information alone, the goal is to generate a video walkthrough of the app's user flow, complete with AI-generated images and audio. Here‚Äôs a look at what the storyboarding tool would look when complete:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### üì¶  Installing packages "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install videodb openai"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### üîë API Keys\n",
    "\n",
    "Before proceeding, ensure access to [VideoDB](https://videodb.io), [OpenAI](https://openai.com), and [ElevenLabs](https://elevenlabs.io) API key. If not, sign up for API access on the respective platforms.\n",
    "\n",
    "> You can get VideoDB's API key from üëâüèº [VideoDB Console](https://console.videodb.io). ( Free for first 50 uploads, **No credit card required!** )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "os.environ[\"OPENAI_API_KEY\"] = \"\"\n",
    "os.environ[\"ELEVEN_LABS_API_KEY\"] = \"\"\n",
    "os.environ[\"VIDEO_DB_API_KEY\"] = \"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### üéô Ô∏èElevenLab's Voice ID \n",
    "\n",
    "You will also need ElevenLab's VoiceID of a Voice that you want to use.\n",
    "\n",
    "Please add [this](https://elevenlabs.io/app/voice-lab/share/eea2654def1e6c5bda5b4ce8f99f8f2c857b71a15cd6188c27d337206ea98177/s6sJbrmNIsT6M7vdjjES) Voice to Your VoiceLab and copy VoiceID from there.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "voiceover_artist_id = \"l0CzJ3s4XFnGAHKDinPf\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Implementation\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### üåê Step 1: Connect to VideoDB\n",
    "Connect to VideoDB using your API key to establish a session for uploading and manipulating video files. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from videodb import connect\n",
    "\n",
    "conn = connect()\n",
    "coll = conn.get_collection()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### üí¨ Step 2: Set up the primary text inputs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "While building an app, these input fields will be exposed to your users and this input will then become the foundation for the rest of this workflow. \n",
    "\n",
    "For the purpose of this tutorial, we are using the sample use case of a user requesting a storyboard for their meditation app via the storyboarding tool that we‚Äôre building."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define Your App\n",
    "app_description = \"A meditation app for busy people with anxiety.\"\n",
    "raw_steps= [\n",
    "    \"Set up profile\",\n",
    "    \"Select preference for theme & music\",\n",
    "    \"Set meditation session timing\",\n",
    "    \"Start the session\"\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### üïπÔ∏è Step 3:  Generating Assets using other Generative AI tools"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This step can be divided into 2 parts:\n",
    "\n",
    "**Step 3.1**: Crafting a prompt for to generate step descriptions, which will ultimately inform the prompts for images and voiceover scripts\n",
    "\n",
    "**Step 3.2**: Creating assets using these prompts:\n",
    "\n",
    "* Step descriptions, image prompts and voiceover scripts from Open AI\n",
    "* Images from DALL-E\n",
    "* Voiceover audio from ElevenLabs\n",
    "* Processing all these assets to be ready for import"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Step 3.1: Writing Prompts for Step Descriptions, Voiceover Scripts and Image Generation\n",
    "___"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, we‚Äôll set up a prompt structure to generate step descriptions for each step defined earlier. Creating a step description helps in setting the context for the image and voice over script prompts.\n",
    "\n",
    "Once that‚Äôs set up, we can focus on the prompts for the images and voiceover scripts for each step. \n",
    "\n",
    "\n",
    "_(Tip: a detailed prompt along with clear specifications about the tone, language, art style, colours and scene descriptions can result in better outputs. The example below illustrates creative ways to ensure consistency in the outputs for each step, while maintaining the standard of quality.)_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prompt_voiceover_scripts(steps, app_description):\n",
    "    prompt = f\"Generate a structured response for {app_description}. in the user journey. This description should capture the essence of the action performed by the user during this step. This application aims to {app_description}. Here are the steps involved in the user journey, Elaborate the each step and involved the specifc steps requird in the stage:\"\n",
    "    for step in steps:\n",
    "        prompt += f\"\"\"\\n-\n",
    "        Create a concise description for the step '{step['step']}' in the user journey. This description should capture the essence of the action performed by the user during this step.\n",
    "        Create a conversational and engaging script for an app where the user is {step['step']}.\n",
    "        Keep it narrative-driven, within two sentences.\n",
    "        \"\"\"\n",
    "    prompt += \"\"\"Return a response in json fromat, with key 'steps', and value being a list of dicts, where each dict has two keys 'step_description' and 'voiceover_script'\n",
    "    {\n",
    "        steps: [\n",
    "        {\n",
    "        'step_description': 'A concise description for the step',\n",
    "        'voiceover_script': 'A conversational and engaging script for the step. Keep it narrative-driven, within two sentences. Add \"-- -- --\" at the very end.'\n",
    "        }\n",
    "        ]\n",
    "    }\n",
    "    \"\"\"\n",
    "    return prompt\n",
    "\n",
    "\n",
    "def prompt_image_generation(step, app_description):\n",
    "    consistent_part = \"Create a stippling black ballpoint pen illustration of a Nigerian woman with a tight afro, living in her minimalist New York apartment. Keep the illustration simple with minimal elements.\"\n",
    "    variable_part = f\"This illustration is a part of a storyboard to explain the user journey of an app built for {app_description}. This image will portray the '{step['step']}' stage in the app. Step description: {step['step_description']}. This illustration is meant for professional storyboarding, so understand the requirements accordingly and create a suitable illustration with the woman as a central character in the frame, but include other supporting props that can indicate that she's in the {step} step in the user flow.\"\n",
    "    prompt = f\"{consistent_part}\\n- {variable_part}\"\n",
    "\n",
    "    return prompt\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Step 3.2: Creating assets using the prompts\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Generate voiceover scripts and step descriptions using OpenAI's language model based on the prompts above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import openai\n",
    "import json\n",
    "\n",
    "def generate_voiceover_scripts(steps):\n",
    "    print(\"\\nGenerating Voiceover script and Step Description...\")\n",
    "    client = openai.OpenAI()\n",
    "    prompt = prompt_voiceover_scripts(steps, app_description)\n",
    "    openai_res = client.chat.completions.create(\n",
    "        model=\"gpt-3.5-turbo\",\n",
    "        messages=[{\"role\": \"system\", \"content\": prompt}],\n",
    "        response_format={\"type\": \"json_object\"},\n",
    "    )\n",
    "    openai_res = json.loads(openai_res.choices[0].message.content)\n",
    "    return openai_res[\"steps\"]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. Converting Voiceover Scripts to Audio with Eleven Labs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "\n",
    "def generate_voiceover_audio(script, file):\n",
    "    print(\"\\nConverting Voiceover Script to Audio...\")\n",
    "    url = f\"https://api.elevenlabs.io/v1/text-to-speech/{voiceover_artist_id}\"\n",
    "    try:\n",
    "        headers = {\"xi-api-key\": os.environ.get(\"ELEVEN_LABS_API_KEY\"), \"Content-Type\": \"application/json\"}\n",
    "        payload = {\n",
    "            \"model_id\": \"eleven_monolingual_v1\",\n",
    "            \"text\": script,\n",
    "            \"voice_settings\": {\"stability\": 0.5, \"similarity_boost\": 0.5},\n",
    "        }\n",
    "        elevenlabs_res = requests.request(\"POST\", url, json=payload, headers=headers)\n",
    "        elevenlabs_res.raise_for_status()\n",
    "        # Save the audio file\n",
    "        with open(file, \"wb\") as f:\n",
    "            f.write(elevenlabs_res.content)\n",
    "        print(f\"Result : voiceover audio saved as {file}\")\n",
    "    except Exception as e:\n",
    "        print(\"An Error occurred while converting the voiceover script to audio: \", e)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. Generating Images with DALL-E"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_image_dalle(step, app_description):\n",
    "    print(\"\\nGenerating Image...\")\n",
    "    prompt = prompt_image_generation(step, app_description)\n",
    "    try:\n",
    "        client = openai.Client()\n",
    "        response = client.images.generate(\n",
    "            model=\"dall-e-3\", prompt=prompt, n=1, size=\"1024x1024\"\n",
    "        )\n",
    "        print(\"Result : \", response.data[0].url)\n",
    "        return response.data[0].url\n",
    "    except Exception as e:\n",
    "        print(f\"An error occurred while generating the image: {e}\")\n",
    "        return None\n",
    "\n",
    "# Code snippet provided for generating images with DALL-E\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4. Final step: Processing the User Journey and Creating Assets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "App Description: A meditation app for busy people with anxiety.\n",
      "\n",
      "Generating Voiceover script and Step Description...\n",
      "\n",
      "---------------------- \n",
      "Processing step: Set up profile\n",
      "\n",
      "Converting Voiceover Script to Audio...\n",
      "Result : voiceover audio saved as voiceover_0.mp3\n",
      "\n",
      "Generating Image...\n",
      "Result :  https://oaidalleapiprodscus.blob.core.windows.net/private/org-map9J6yCG74QUls8JLyE2N7r/user-kqCy428rS4ZPTYHJCYV6HouY/img-Tuf1AnzGC3PxfXGt5SCRqyai.png?st=2024-05-06T10%3A39%3A41Z&se=2024-05-06T12%3A39%3A41Z&sp=r&sv=2021-08-06&sr=b&rscd=inline&rsct=image/png&skoid=6aaadede-4fb3-4698-a8f6-684d7786b067&sktid=a48cca56-e6da-484e-a814-9c849652bcb3&skt=2024-05-05T21%3A27%3A22Z&ske=2024-05-06T21%3A27%3A22Z&sks=b&skv=2021-08-06&sig=IqQxyqDZJXD5sk7G%2BRK3m8C3MjbivpRGVD4b2089L4I%3D\n",
      "\n",
      "---------------------- \n",
      "Processing step: Select preference for theme & music\n",
      "\n",
      "Converting Voiceover Script to Audio...\n",
      "Result : voiceover audio saved as voiceover_1.mp3\n",
      "\n",
      "Generating Image...\n",
      "Result :  https://oaidalleapiprodscus.blob.core.windows.net/private/org-map9J6yCG74QUls8JLyE2N7r/user-kqCy428rS4ZPTYHJCYV6HouY/img-nlkl95LkB2FToFFAhSCElJ9n.png?st=2024-05-06T10%3A40%3A00Z&se=2024-05-06T12%3A40%3A00Z&sp=r&sv=2021-08-06&sr=b&rscd=inline&rsct=image/png&skoid=6aaadede-4fb3-4698-a8f6-684d7786b067&sktid=a48cca56-e6da-484e-a814-9c849652bcb3&skt=2024-05-05T19%3A35%3A53Z&ske=2024-05-06T19%3A35%3A53Z&sks=b&skv=2021-08-06&sig=GgH7xEtz1uwcFl8g5fSyFeTy4ZX9AHSNd039TEfOhLY%3D\n",
      "\n",
      "---------------------- \n",
      "Processing step: Set meditation session timing\n",
      "\n",
      "Converting Voiceover Script to Audio...\n",
      "Result : voiceover audio saved as voiceover_2.mp3\n",
      "\n",
      "Generating Image...\n",
      "Result :  https://oaidalleapiprodscus.blob.core.windows.net/private/org-map9J6yCG74QUls8JLyE2N7r/user-kqCy428rS4ZPTYHJCYV6HouY/img-Zjrjdm8kY1zROkOm5bdsdJSa.png?st=2024-05-06T10%3A40%3A20Z&se=2024-05-06T12%3A40%3A20Z&sp=r&sv=2021-08-06&sr=b&rscd=inline&rsct=image/png&skoid=6aaadede-4fb3-4698-a8f6-684d7786b067&sktid=a48cca56-e6da-484e-a814-9c849652bcb3&skt=2024-05-05T21%3A27%3A22Z&ske=2024-05-06T21%3A27%3A22Z&sks=b&skv=2021-08-06&sig=nBHrUzwJSD3U5Bt7HpQJacjHQAdF3FCQM6/qYra4zEM%3D\n",
      "\n",
      "---------------------- \n",
      "Processing step: Start the session\n",
      "\n",
      "Converting Voiceover Script to Audio...\n",
      "Result : voiceover audio saved as voiceover_3.mp3\n",
      "\n",
      "Generating Image...\n",
      "Result :  https://oaidalleapiprodscus.blob.core.windows.net/private/org-map9J6yCG74QUls8JLyE2N7r/user-kqCy428rS4ZPTYHJCYV6HouY/img-pyiqRgrIBplzjAFxMdNKNtoz.png?st=2024-05-06T10%3A40%3A48Z&se=2024-05-06T12%3A40%3A48Z&sp=r&sv=2021-08-06&sr=b&rscd=inline&rsct=image/png&skoid=6aaadede-4fb3-4698-a8f6-684d7786b067&sktid=a48cca56-e6da-484e-a814-9c849652bcb3&skt=2024-05-05T22%3A19%3A14Z&ske=2024-05-06T22%3A19%3A14Z&sks=b&skv=2021-08-06&sig=rk4xIAEXAPcBFg37kSgi5UHl2A8BRjNRiIJKMipygSg%3D\n"
     ]
    }
   ],
   "source": [
    "def process_user_journey(steps, app_description):\n",
    "    print(\"App Description:\", app_description)\n",
    "\n",
    "    step_scripts = generate_voiceover_scripts(steps)\n",
    "    for index, step in enumerate(step_scripts):\n",
    "        steps[index][\"step_description\"] = step[\"step_description\"]\n",
    "        steps[index][\"voiceover_script\"] = step[\"voiceover_script\"]\n",
    "\n",
    "    for index, step in enumerate(steps):\n",
    "        print(f\"\\n---------------------- \\nProcessing step: {step['step']}\")\n",
    "\n",
    "        voiceover_script = step[\"voiceover_script\"]\n",
    "        if voiceover_script:\n",
    "            voiceover_file_name = f\"voiceover_{index}.mp3\"\n",
    "            step[\"voiceover_filename\"] = voiceover_file_name\n",
    "            generate_voiceover_audio(voiceover_script, voiceover_file_name)\n",
    "        image_url = generate_image_dalle(step, app_description)\n",
    "        if image_url:\n",
    "            step[\"image_url\"] = image_url\n",
    "\n",
    "steps = []\n",
    "for app_step in raw_steps:\n",
    "    steps.append({\"step\": app_step})\n",
    "process_user_journey(steps, app_description)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### üé• Step 4: Combining Assets and Creating the Video Walkthrough\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Uploading Generated Assets to VideoDB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "----------------------\n",
      "Processing step: Set up profile\n",
      "\n",
      "Uploading Image...\n",
      "Uploaded Image\n",
      "\n",
      "Uploading Voiceover Audio...\n",
      "Uploaded Voiceover Audio\n",
      "\n",
      "----------------------\n",
      "Processing step: Select preference for theme & music\n",
      "\n",
      "Uploading Image...\n",
      "Uploaded Image\n",
      "\n",
      "Uploading Voiceover Audio...\n",
      "Uploaded Voiceover Audio\n",
      "\n",
      "----------------------\n",
      "Processing step: Set meditation session timing\n",
      "\n",
      "Uploading Image...\n",
      "Uploaded Image\n",
      "\n",
      "Uploading Voiceover Audio...\n",
      "Uploaded Voiceover Audio\n",
      "\n",
      "----------------------\n",
      "Processing step: Start the session\n",
      "\n",
      "Uploading Image...\n",
      "Uploaded Image\n",
      "\n",
      "Uploading Voiceover Audio...\n",
      "Uploaded Voiceover Audio\n"
     ]
    }
   ],
   "source": [
    "from videodb import MediaType\n",
    "\n",
    "for step in steps:\n",
    "    print(f\"\"\"\\n----------------------\\nProcessing step: {step['step']}\"\"\")\n",
    "\n",
    "    print(\"\\nUploading Image...\")\n",
    "    image = coll.upload(url=step[\"image_url\"], media_type=MediaType.image)\n",
    "    print(\"Uploaded Image\")\n",
    "\n",
    "    print(\"\\nUploading Voiceover Audio...\")\n",
    "    audio = coll.upload(file_path=step[\"voiceover_filename\"])\n",
    "    print(\"Uploaded Voiceover Audio\")\n",
    "\n",
    "    step[\"image_id\"] = image.id\n",
    "    step[\"audio_id\"] = audio.id\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. Creating Timeline for the Video Storyboard in VideoDB"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create a timeline to sequence the assets and create a dynamic video walkthrough. We will need a video in order to create a timeline, so we‚Äôll be using this [blank video](https://www.youtube.com/watch?v=4dW1ybhA5bM) as a base. This can be used as a background for the generated images too, so feel free to replace this url with any video of your choice.\n",
    "\n",
    "_Bonus: Use [Text Assets](https://coda.io/d/_dnIYgjBK4eB/_suXI9) to display the step name in the user flow. It can be customised using [Text Styling](https://coda.io/d/_dnIYgjBK4eB/_sulS5)_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create Timeline in VideoDB\n",
    "from videodb.asset import VideoAsset, ImageAsset, AudioAsset, TextAsset\n",
    "from videodb.timeline import Timeline\n",
    "from videodb import TextStyle\n",
    "\n",
    "timeline = Timeline(conn)\n",
    "\n",
    "seeker = 0\n",
    "\n",
    "# Create Asset for Image and Audio Asset\n",
    "for step in steps:\n",
    "    audio = coll.get_audio(step[\"audio_id\"])\n",
    "    image = coll.get_image(step[\"image_id\"])\n",
    "\n",
    "    audio_duration = float(audio.length)\n",
    "\n",
    "    image_asset = ImageAsset(\n",
    "        image.id, duration=audio_duration, x=300, y=0, width=720, height=720\n",
    "    )\n",
    "    audio_asset = AudioAsset(audio.id, disable_other_tracks=True)\n",
    "    text_asset = TextAsset(\n",
    "        step[\"step\"],\n",
    "        duration=audio_duration,\n",
    "        style=TextStyle(\n",
    "            y=\"h - 150\",\n",
    "            font=\"League Spartan\",\n",
    "            fontsize=56,\n",
    "            fontcolor=\"Snow\",\n",
    "            boxcolor=\"OrangeRed\",\n",
    "            boxborderw=40,\n",
    "        ),\n",
    "    )\n",
    "    timeline.add_overlay(seeker, audio_asset)\n",
    "    timeline.add_overlay(seeker, image_asset)\n",
    "    timeline.add_overlay(seeker, text_asset)\n",
    "\n",
    "    seeker += audio_duration\n",
    "\n",
    "# Upload a base Video, that will be used as a background\n",
    "base_vid = coll.upload(url=\"https://www.youtube.com/watch?v=4dW1ybhA5bM\")\n",
    "base_vid_aset = VideoAsset(base_vid.id, end=seeker)\n",
    "timeline.add_inline(base_vid_aset)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Previewing the Final Video Walkthrough"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'https://console.videodb.io/player?url=https://dseetlpshk2tb.cloudfront.net/v3/published/manifests/f474aec8-441f-43b1-b5fd-d243f262f64a.m3u8'"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from videodb import play_stream\n",
    "\n",
    "# Preview Video in VideoDB\n",
    "stream_url = timeline.generate_stream()\n",
    "play_stream(stream_url)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Congratulations! You've successfully created the structure for an app that can generate automated, prompt-based videos using VideoDB, DALL-E, OpenAI, and Eleven Labs. Explore different prompts and AI models to customize the video to your specific app and audience. \n",
    "\n",
    "\n",
    "_The better the prompts, the better the end output üòâ_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
