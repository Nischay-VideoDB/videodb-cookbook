{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# üîä Lovo x VideoDB: Adding AI Generated voiceovers to silent footage"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a href=\"https://colab.research.google.com/github/video-db/videodb-cookbook/blob/main/examples/Lovo_Voiceover_1.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Overview"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Crafting AI content and blending results from multiple tools can be super-difficult and time-intensive. Manual execution of these tasks is even more challenging. But what if you could accomplish everything with just a few lines of code?\n",
    "\n",
    "Unlock the full potential of VideoDB's seamless integration with leading AI technologies like `OpenAI` and `LOVO` to effortlessly create engaging AI generated voiceovers. This tutorial showcases the powerful technical capabilities of VideoDB platform to streamline the process of adding dynamic AI generated narrations to a silent footage. \n",
    "\n",
    "Let‚Äôs experience the ease of use and limitless possibilities as you begin a fun experiment to create an exciting narration for [this](https://youtu.be/RcRjY5kzia8) footage, all within the VideoDB environment.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](https://raw.githubusercontent.com/video-db/videodb-cookbook-assets/main/images/examples/Lovo_Voiceover_1.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### üì¶  Installing packages "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ensure you have the necessary packages installed:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install openai\n",
    "%pip install videodb"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### üîë API Keys"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before proceeding, ensure access to [VideoDB](https://videodb.io), [OpenAI](https://openai.com), and [LOVO](https://lovo.ai/) API key. If not, sign up for API access on the respective platforms.\n",
    "\n",
    "> Get your API key from [VideoDB Console](https://console.videodb.io). ( Free for first 50 uploads, **No credit card required** ) üéâ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "os.environ[\"OPENAI_API_KEY\"] = \"\"\n",
    "os.environ[\"LOVO_API_KEY\"] = \"\"\n",
    "os.environ[\"VIDEO_DB_API_KEY\"] = \"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> **üóíÔ∏è Note for Free-tier Users of LOVO**\n",
    ">  \n",
    "> Users without a paid plan of Lovo might face some issues while using API. Please reach out to their support team in case of issues with the LOVO API malfunction."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### üéôÔ∏è  Lovo's Speaker ID  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You will also need LOVO's SpeakerID of a Voice that you want to use. \n",
    "\n",
    "For this demo, we‚Äôll choose a cheerful voice from Lovo's Voice Library. You can choose this based on the style of voiceovers you wish to create.\n",
    "\n",
    "Checkout [Lovo Guide](https://lovo.ai/post/getting-started-with-genny-api) if you want to select custom speaker"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "speaker_id = \"640f477d2babeb0024be422b\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Implementation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "### üåê Step 1: Connect to VideoDB\n",
    "Begin by establishing a connection to VideoDB using your API key"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "from videodb import connect\n",
    "\n",
    "# Connect to VideoDB using your API key\n",
    "conn = connect()\n",
    "coll = conn.get_collection()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### üé• Step 2: Upload Video"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Upload a video by URL (replace the url with your video)\n",
    "video = conn.upload(url='https://youtu.be/RcRjY5kzia8')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### üîç Step 3: Analyze Scenes and Generate Scene Descriptions\n",
    "\n",
    "Start by analyzing the scenes within your Video using VideoDB's scene indexing capabilities. This will provide context for generating the script prompt."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "video.index_scenes()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's view the description of first scene of the video"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 - 9.7\n",
      "The image is a highly pixelated or low-resolution photo predominated by various shades of blue. There is no distinguishable subject due to heavy pixelation, causing the content to appear abstract. The pattern seems chaotic, with irregularly shaped and sized blocks giving an impression of a digital mosaic. There are subtle variations in color, with some pixels exhibiting a teal or turquoise hue, while others are a deeper navy blue, together creating a textured appearance. The image's focus is unclear, causing the pixels to blur together, further obscuring any possible details and making the overall content of the photograph indiscernible.\n"
     ]
    }
   ],
   "source": [
    "scenes = video.get_scenes()\n",
    "print(f\"{scenes[0]['start']} - {scenes[0]['end']}\")\n",
    "print(scenes[0][\"response\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 4: Generate Voiceover Script with LLM\n",
    "Combine scene descriptions with a script prompt, instructing LLM to create a playful narration suitable for kids.\n",
    "\n",
    "\n",
    "This script prompt can be refined and tweaked to generate the most suitable output. Check out [these examples](https://www.youtube.com/playlist?list=PLhxAMFLSSK03rsPTjRv1LbAXHQpNN6BS0) to explore more use cases."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import openai\n",
    "\n",
    "client = openai.OpenAI()\n",
    "\n",
    "script_prompt = \"Here's the data from a scene index for a video about the underwater world. Study this and then generate a synced script based on the description below. Make sure the script is in the language, voice and style of Santa Claus\"\n",
    "\n",
    "full_prompt = script_prompt + \"\\n\\n\"\n",
    "for scene in scenes:\n",
    "  full_prompt += f\"- {scene}\\n\"\n",
    "\n",
    "openai_res = client.chat.completions.create(\n",
    "    model=\"gpt-3.5-turbo\",\n",
    "    messages=[{\"role\": \"system\", \"content\": full_prompt}],\n",
    ")\n",
    "voiceover_script = openai_res.choices[0].message.content"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### üé§ Step 5: Generate Voiceover Audio with LOVO "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Due to Lovo API‚Äôs limitation, we will have to create chunks of voiceover script of 500 characters each"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "chunk_size = 500\n",
    "chunks = [voiceover_script[i:i+chunk_size] for i in range(0, len(voiceover_script), chunk_size)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Utilize the generated script to synthesize a cheerful and fun narration for kids using Lovo's API:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import time \n",
    "\n",
    "\n",
    "# Call Lovo API to generate voiceover\n",
    "url = \"https://api.genny.lovo.ai/api/v1/tts\"\n",
    "headers = {\n",
    "    \"accept\": \"application/json\",\n",
    "    \"content-type\": \"application/json\",\n",
    "    \"X-API-KEY\": os.environ.get(\"LOVO_API_KEY\")\n",
    "}\n",
    "\n",
    "# Initiate TTS Job for each Chunk\n",
    "outputs = []\n",
    "for chunk in chunks:\n",
    "    payload = {\n",
    "        \"text\": chunk,\n",
    "        \"speaker\": speaker_id\n",
    "    }\n",
    "    lovo_res = requests.request(\"POST\", url, json=payload, headers=headers)\n",
    "    print(lovo_res.json())\n",
    "    job_id = lovo_res.json()[\"id\"]\n",
    "    outputs.append({\"job_id\": job_id})\n",
    "\n",
    "# Keep Polling the API to check outputs\n",
    "poll_time = 1\n",
    "for output in outputs:\n",
    "    completed = False\n",
    "    while not completed:\n",
    "        lovo_res = requests.request(\"GET\", f\"{url}/{output['job_id']}\", headers=headers)\n",
    "        lovo_res = lovo_res.json()['data'][0]\n",
    "        completed = lovo_res[\"status\"] == \"succeeded\"\n",
    "        if completed:\n",
    "            output[\"audio_url\"] = lovo_res[\"urls\"][0]\n",
    "            completed = True\n",
    "            break\n",
    "        else:\n",
    "            time.sleep(poll_time)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### üé¨ Step 6: Add Voiceover to Video with VideoDB"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In order to use the voiceover generated above, let's upload the audio file (voiceover) to VideoDB first"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Audio Uploaded with id a-7f071983-4eac-4b90-ab64-fdbe82e6d3cc\n",
      "Audio Uploaded with id a-401d6309-45c6-4355-85d1-eae8712e1c04\n",
      "Audio Uploaded with id a-ecadee95-edb6-476d-8e89-82b65c5ed157\n",
      "Audio Uploaded with id a-92a01c89-1cf6-4c2c-ba75-3ecae238e616\n",
      "Audio Uploaded with id a-601f01e4-0f01-4d41-a4ad-a2aaa66704f4\n",
      "Audio Uploaded with id a-37c76474-dc4c-4be2-a1a6-55d8144f678e\n"
     ]
    }
   ],
   "source": [
    "\n",
    "for output in outputs:\n",
    "    audio = coll.upload(url=output[\"audio_url\"])\n",
    "    output[\"audio_id\"] = audio.id\n",
    "    output[\"audio_length\"] = float(audio.length)\n",
    "    print(\"Audio Uploaded with id\", audio.id)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, add the AI-generated voiceover to the original footage using VideoDB's [timeline feature](https://docs.videodb.io/version-0-0-3-timeline-and-assets-44)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "from videodb.timeline import Timeline\n",
    "from videodb.asset import VideoAsset, AudioAsset\n",
    "\n",
    "# Create a timeline object\n",
    "timeline = Timeline(conn)\n",
    "\n",
    "# Add the video asset to the timeline for playback\n",
    "video_asset = VideoAsset(asset_id=video.id)\n",
    "timeline.add_inline(asset=video_asset)\n",
    "\n",
    "seek = 0\n",
    "for output in outputs:\n",
    "    audio_asset = AudioAsset(asset_id=output[\"audio_id\"])\n",
    "    timeline.add_overlay(start=seek, asset=audio_asset)\n",
    "    seek += output['audio_length']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ü™Ñ Step 7: Review and Share\n",
    "\n",
    "Preview the video with the integrated voiceover to ensure it functions correctly.   \n",
    "Once satisfied with the cheer quotient in the narration, share it to spread joy among young viewers!\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from videodb import play_stream\n",
    "\n",
    "stream_url = timeline.generate_stream()\n",
    "play_stream(stream_url)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### üéâ Conclusion:\n",
    "Congratulations! You have successfully automated the process of creating custom and personalized voiceovers based on a simple prompt and raw video footage using VideoDB, OpenAI, and LOVO.\n",
    "\n",
    "Experiment with different prompts and scene analysis techniques to further improve the quality and accuracy of the voiceovers. Enjoy creating captivating narratives with AI-powered voiceovers using VideoDB! \n",
    "\n",
    "For more such explorations, refer to the [documentation of VideoDB](https://docs.videodb.io/) and join the VideoDB community on [GitHub](https://github.com/video-db) or [Discord](https://discord.com/invite/py9P639jGz) for support and collaboration.\n",
    "\n",
    "We're excited to see your creations, so we welcome you to share your creations via [Discord](https://discord.com/invite/py9P639jGz), [LinkedIn](https://www.linkedin.com/company/videodb) or [Twitter](https://twitter.com/videodb_io)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
