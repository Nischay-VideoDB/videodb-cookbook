{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# üîä Lovo x VideoDB: Adding AI Generated voiceovers to silent footage"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a href=\"https://colab.research.google.com/github/video-db/videodb-cookbook/blob/nb/lovo-1/examples/Lovo_Voiceover_1.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Overview"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](https://raw.githubusercontent.com/video-db/videodb-cookbook-assets/main/images/examples/Lovo_Voiceover_1.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### üì¶  Installing packages "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install openai\n",
    "%pip install videodb"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### üîë API Keys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "os.environ[\"OPENAI_API_KEY\"] = \"\"\n",
    "os.environ[\"LOVO_API_KEY\"] = \"\"\n",
    "os.environ[\"VIDEO_DB_API_KEY\"] = \"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### üéôÔ∏è  Lovo's Speaker ID  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "voiceover_artist_id = \"640f477d2babeb0024be422b\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Implementation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "### üåê Step 1: Connect to VideoDB\n",
    "Connect to VideoDB using your API key to establish a session for uploading and manipulating video files."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "from videodb import connect\n",
    "\n",
    "# Connect to VideoDB using your API key\n",
    "conn = connect()\n",
    "coll = conn.get_collection()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### üé• Step 2: Upload Video"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Upload a video by URL (replace the url with your video)\n",
    "video = conn.upload(url='https://youtu.be/RcRjY5kzia8')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### üîç Step 3: Analyze Scenes and Generate Scene Descriptions\n",
    "\n",
    "Start by analyzing the scenes within your Video using VideoDB's scene indexing capabilities. This will provide context for generating the script prompt."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "video.index_scenes()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's view the description of first scene of the video"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 - 9.7\n",
      "The image is a highly pixelated or low-resolution photo predominated by various shades of blue. There is no distinguishable subject due to heavy pixelation, causing the content to appear abstract. The pattern seems chaotic, with irregularly shaped and sized blocks giving an impression of a digital mosaic. There are subtle variations in color, with some pixels exhibiting a teal or turquoise hue, while others are a deeper navy blue, together creating a textured appearance. The image's focus is unclear, causing the pixels to blur together, further obscuring any possible details and making the overall content of the photograph indiscernible.\n"
     ]
    }
   ],
   "source": [
    "scenes = video.get_scenes()\n",
    "print(f\"{scenes[0]['start']} - {scenes[0]['end']}\")\n",
    "print(scenes[0][\"response\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 4: Generate Voiceover Script with LLM\n",
    "Combine scene descriptions with the script prompt, instructing LLM to create a voiceover script in David Attenborough's style.\n",
    "\n",
    "This script prompt can be refined and tweaked to generate the most suitable output. Check out [these examples](https://www.youtube.com/playlist?list=PLhxAMFLSSK03rsPTjRv1LbAXHQpNN6BS0) to explore more use cases."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import openai\n",
    "\n",
    "client = openai.OpenAI()\n",
    "\n",
    "script_prompt = \"Here's the data from a scene index for a video about the underwater world. Study this and then generate a synced script based on the description below. Make sure the script is in the language, voice and style of Sir David Attenborough\"\n",
    "\n",
    "full_prompt = script_prompt + \"\\n\\n\"\n",
    "for scene in scenes:\n",
    "  full_prompt += f\"- {scene}\\n\"\n",
    "\n",
    "openai_res = client.chat.completions.create(\n",
    "    model=\"gpt-3.5-turbo\",\n",
    "    messages=[{\"role\": \"system\", \"content\": full_prompt}],\n",
    ")\n",
    "voiceover_script = openai_res.choices[0].message.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "chunk_size = 500\n",
    "chunks = [voiceover_script[i:i+chunk_size] for i in range(0, len(voiceover_script), chunk_size)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### üé§ Step 5: Generate Voiceover Audio with LOVO "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import time \n",
    "\n",
    "\n",
    "# Call Lovo API to generate voiceover\n",
    "url = \"https://api.genny.lovo.ai/api/v1/tts\"\n",
    "headers = {\n",
    "    \"accept\": \"application/json\",\n",
    "    \"content-type\": \"application/json\",\n",
    "    \"X-API-KEY\": os.environ.get(\"LOVO_API_KEY\")\n",
    "}\n",
    "\n",
    "outputs = []\n",
    "for chunk in chunks:\n",
    "    payload = {\n",
    "        \"text\": chunk,\n",
    "        \"speaker\": voiceover_artist_id\n",
    "    }\n",
    "    lovo_res = requests.request(\"POST\", url, json=payload, headers=headers)\n",
    "    job_id = lovo_res.json()[\"id\"]\n",
    "    outputs.append({\"job_id\": job_id})\n",
    "\n",
    "poll_time = 1\n",
    "for output in outputs:\n",
    "    completed = False\n",
    "    while not completed:\n",
    "        lovo_res = requests.request(\"GET\", f\"{url}/{output['job_id']}\", headers=headers)\n",
    "        lovo_res = lovo_res.json()['data'][0]\n",
    "        completed = lovo_res[\"status\"] == \"succeeded\"\n",
    "        if completed:\n",
    "            output[\"audio_url\"] = lovo_res[\"urls\"][0]\n",
    "            completed = True\n",
    "            break\n",
    "        else:\n",
    "            time.sleep(poll_time)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### üé¨ Step 6: Add Voiceover to Video with VideoDB"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In order to use the voiceover generated above, let's upload the audio file (voiceover) to VideoDB first"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Audio Uploaded with id a-7f071983-4eac-4b90-ab64-fdbe82e6d3cc\n",
      "Audio Uploaded with id a-401d6309-45c6-4355-85d1-eae8712e1c04\n",
      "Audio Uploaded with id a-ecadee95-edb6-476d-8e89-82b65c5ed157\n",
      "Audio Uploaded with id a-92a01c89-1cf6-4c2c-ba75-3ecae238e616\n",
      "Audio Uploaded with id a-601f01e4-0f01-4d41-a4ad-a2aaa66704f4\n",
      "Audio Uploaded with id a-37c76474-dc4c-4be2-a1a6-55d8144f678e\n"
     ]
    }
   ],
   "source": [
    "\n",
    "for output in outputs:\n",
    "    audio = coll.upload(url=output[\"audio_url\"])\n",
    "    output[\"audio_id\"] = audio.id\n",
    "    output[\"audio_length\"] = float(audio.length)\n",
    "    print(\"Audio Uploaded with id\", audio.id)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, add the AI-generated voiceover to the original footage using VideoDB's [timeline feature](https://docs.videodb.io/version-0-0-3-timeline-and-assets-44)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "from videodb.timeline import Timeline\n",
    "from videodb.asset import VideoAsset, AudioAsset\n",
    "\n",
    "# Create a timeline object\n",
    "timeline = Timeline(conn)\n",
    "\n",
    "# Add the video asset to the timeline for playback\n",
    "video_asset = VideoAsset(asset_id=video.id)\n",
    "timeline.add_inline(asset=video_asset)\n",
    "\n",
    "seek = 0\n",
    "for output in outputs:\n",
    "    audio_asset = AudioAsset(asset_id=output[\"audio_id\"])\n",
    "    timeline.add_overlay(start=seek, asset=audio_asset)\n",
    "    seek += output['audio_length']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ü™Ñ Step 7: Review and Share\n",
    "Preview the video with the integrated voiceover to ensure it functions correctly.   \n",
    "Once satisfied, generate a stream of the video and share the link for others to view and enjoy this wholesome creation!\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'https://console.videodb.io/player?url=https://dseetlpshk2tb.cloudfront.net/v3/published/manifests/b91a79b5-1ebb-4876-ab5d-d5c2380a099d.m3u8'"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from videodb import play_stream\n",
    "\n",
    "stream_url = timeline.generate_stream()\n",
    "play_stream(stream_url)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### üéâ Conclusion:\n",
    "Congratulations! You have successfully automated the process of creating custom and personalized voiceovers based on a simple prompt and raw video footage using VideoDB, OpenAI, and ElevenLabs.\n",
    "\n",
    "By leveraging advanced AI technologies, you can enhance the storytelling and immersive experience of your video content. Experiment with different prompts and scene analysis techniques to further improve the quality and accuracy of the voiceovers. Enjoy creating captivating narratives with AI-powered voiceovers using VideoDB! \n",
    "\n",
    "For more such explorations, refer to the [documentation of VideoDB](https://docs.videodb.io/) and join the VideoDB community on [GitHub](https://github.com/video-db) or [Discord](https://discord.com/invite/py9P639jGz) for support and collaboration.\n",
    "\n",
    "We're excited to see your creations, so we welcome you to share your creations via [Discord](https://discord.com/invite/py9P639jGz), [LinkedIn](https://www.linkedin.com/company/videodb) or [Twitter](https://twitter.com/videodb_io)."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
