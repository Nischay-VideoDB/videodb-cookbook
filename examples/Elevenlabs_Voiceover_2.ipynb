{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# üîä Elevating Trailers with Automated Narration"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a href=\"https://colab.research.google.com/github/video-db/videodb-cookbook/blob/main/examples/Elevenlabs_Voiceover_2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introduction \n",
    "\n",
    "Narration is the heartbeat of trailers, injecting excitement and intrigue into every frame. With [VideoDB](https://videodb.io), [OpenAI](https://openai.com), and [ElevenLabs](https://elevenlabs.io) at your fingertips, adding narration to trailers becomes a thrilling adventure. This tutorial will guide you through the exhilarating process of seamlessly integrating narration into trailers using these powerful tools."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### üì¶  Installing packages "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install openai\n",
    "%pip install videodb"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### üîë API keys\n",
    "Before proceeding, ensure access to [VideoDB](https://videodb.io), [OpenAI](https://openai.com), and [ElevenLabs](https://elevenlabs.io) API key. If not, sign up for API access on the respective platforms.\n",
    "\n",
    "> Get your API key from [VideoDB Console](https://console.videodb.io). ( Free for first 50 uploads, **No credit card required** ) üéâ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "os.environ[\"OPENAI_API_KEY\"] = \"\"\n",
    "os.environ[\"ELEVEN_LABS_API_KEY\"] = \"\"\n",
    "os.environ[\"VIDEO_DB_API_KEY\"] = \"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### üéôÔ∏è  ElevenLab's Voice ID  \n",
    "You will also need ElevenLab's VoiceID of a Voice that you want to use.\n",
    "\n",
    "For this demo, we will be using [Sam Elliot's Voice](https://elevenlabs.io/app/voice-lab/share/bcf1f77ee30ba698ec2808b47188b4189a69c862c073d704fde7034608eeaec5/nRjJQMMnjuyMXVyDw9TC). ElevenLabs has a large variety of voices to choose from (browse them [here](https://elevenlabs.io/voice-library)). Once finalized, copy the Voice ID from ElevenLabs and link it here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "voiceover_artist_id = \"VOICEOVER_ARTIST_ID\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tutorial Walkthrough"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "### üìã Step 1: Connect to VideoDB\n",
    "Gear up by establishing a connection to VideoDB using your API key to manage and make the most of you video library with unparalleled efficiency."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from videodb import connect\n",
    "\n",
    "# Connect to VideoDB using your API key\n",
    "conn = connect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### üé¨ Step 2: Upload the Trailer\n",
    "Upload the trailer video to VideoDB for further processing. This creates the base video asset that we shall use later in this tutorial."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "video = conn.upload(url='https://www.youtube.com/watch?v=WQmGwmc-XUY')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### üîç Step 3: Analyze Scenes and Generate Scene Descriptions\n",
    "\n",
    "Start by analyzing the scenes within your Video using VideoDB's scene indexing capabilities. This will provide context for generating the script prompt."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "video.index_scenes()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's view the description of first scene from the video"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 - 0.7090416666666666\n",
      "The image captures a fiery blaze, a dynamic dance of flames in vivid shades of orange, gold, and red. Light flickers intensely, radiance expanding, contracting with the fire's rhythm. No specific source is visible; the fire dominates entirely, filling the frame with energetic movement. The luminosity suggests a fierce heat, powerful enough to demand respect and caution. Each tongue of flame is seemingly alive, almost writhing against a darker, indistinct background. This could be a natural fire or a controlled blaze‚Äîthere‚Äôs no context to indicate its origin. Amidst the searing heat, the flames create a mesmeric, albeit destructive, spectacle.\n"
     ]
    }
   ],
   "source": [
    "scenes = video.get_scenes()\n",
    "print(f\"{scenes[0]['start']} - {scenes[0]['end']}\")\n",
    "print(scenes[0][\"response\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### üîä Step 4: Generate Narration Script with LLM\n",
    "Here, we use OpenAI‚Äôs GPT to build context around the scene descriptions above, and generate a fitting narration script for the visuals."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate narration script with ChatGPT\n",
    "import openai\n",
    "\n",
    "client = openai.OpenAI()\n",
    "\n",
    "script_prompt = \"Craft a dynamic narration script for this trailer, incorporating scene descriptions to enhance storytelling. Ensure that the narration aligns seamlessly with the timestamps provided in the scene index. Do not include any annotations in the output script\"\n",
    "\n",
    "full_prompt = script_prompt + \"\\n\\n\"\n",
    "for scene in scenes:\n",
    "  full_prompt += f\"- {scene}\\n\"\n",
    "\n",
    "openai_res = client.chat.completions.create(\n",
    "    model=\"gpt-3.5-turbo\",\n",
    "    messages=[{\"role\": \"system\", \"content\": full_prompt}],\n",
    ")\n",
    "voiceover_script = openai_res.choices[0].message.content\n",
    "\n",
    "# If you have ElevenLab's paid plan remove the :2500 limit on voiceover script.\n",
    "voiceover_script = voiceover_script[:2500]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can refine the narration script prompt to ensure synchronization with timestamps in the scene index, optimizing the storytelling experience."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### üéôÔ∏è Step 5: Generate Narration Audio with elevenlabs.io\n",
    "Prepare to be dazzled as you synthesize the narration audio using elevenlabs.io API, tailored to match the trailer's pulse-pounding rhythm.\n",
    "\n",
    "Note: for this step, you will need a specific voice ID that fits perfectly with the vibe of your trailer. In our example, we have used this voice that resembles the vocal quality and style that of Sam Elliott. You can find a voice suitable for your trailer in the ElevenLabs Voice Library."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "\n",
    "\n",
    "# Call ElevenLabs API to generate voiceover\n",
    "url = f\"https://api.elevenlabs.io/v1/text-to-speech/{voiceover_artist_id}\"\n",
    "headers = {\n",
    "    \"xi-api-key\": os.environ.get(\"ELEVEN_LABS_API_KEY\"),\n",
    "    \"Content-Type\": \"application/json\"\n",
    "}\n",
    "payload = {\n",
    "    \"model_id\": \"eleven_monolingual_v1\",\n",
    "    \"text\": voiceover_script,\n",
    "    \"voice_settings\": {\n",
    "        \"stability\": 0.5,\n",
    "        \"similarity_boost\": 0.5\n",
    "    }\n",
    "}\n",
    "elevenlabs_res = requests.request(\"POST\", url, json=payload, headers=headers)\n",
    "\n",
    "# Save the audio file\n",
    "audio_file = \"audio.mp3\"\n",
    "CHUNK_SIZE = 1024\n",
    "with open(audio_file, 'wb') as f:\n",
    "    for chunk in elevenlabs_res.iter_content(chunk_size=CHUNK_SIZE):\n",
    "        if chunk:\n",
    "            f.write(chunk)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### üé¨ Step 6: Add Voiceover to Video with VideoDB"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Upload the audio file (voiceover) to VideoDB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "audio = conn.upload(file_path=audio_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### üé• Step 7: Add Narration to Trailer with VideoDB\n",
    "Combine the narration audio with the trailer using VideoDB's timeline feature."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from videodb.timeline import Timeline\n",
    "from videodb.asset import VideoAsset, AudioAsset\n",
    "\n",
    "timeline = Timeline(conn)\n",
    "\n",
    "video_asset = VideoAsset(asset_id=video.id, start=0)\n",
    "\n",
    "audio_asset1 = AudioAsset(asset_id=audio.id, start=5, end=25.5, disable_other_tracks=False)\n",
    "audio_asset2 = AudioAsset(asset_id=audio.id, start=35, end=49, disable_other_tracks=False)\n",
    "\n",
    "# add asset overlay\n",
    "timeline.add_inline(asset=video_asset)\n",
    "timeline.add_overlay(start=4, asset=audio_asset1)\n",
    "timeline.add_overlay(start=35, asset=audio_asset2)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ü™Ñ Step 8: Review and Share\n",
    "Preview the trailer with the integrated narration to ensure it aligns with your vision. Once satisfied, share the trailer with others to experience the enhanced storytelling.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'https://console.videodb.io/player?url=https://dseetlpshk2tb.cloudfront.net/v3/published/manifests/fea6943a-0ac6-4a13-9309-4df35e41f6f7.m3u8'"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from videodb import play_stream\n",
    "\n",
    "stream_url = timeline.generate_stream()\n",
    "play_stream(stream_url)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üé¨ Bonus\n",
    "-----"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Add Movie Poster at the End\n",
    "\n",
    "To incorporate adding a movie poster as a bonus section at the end of the trailer using VideoDB, you can follow these steps (you‚Äôll find the code snippet for the same below):\n",
    "\n",
    "1. We first import the necessary module for handling Image Assets. \n",
    "2. Then, we upload the movie poster image to VideoDB. \n",
    "3. Next, we create an Image Asset with the uploaded poster image, specifying its dimensions and duration. \n",
    "4. Finally, we add the movie poster as an overlay at the end of the video timeline."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from videodb.asset import ImageAsset\n",
    "from videodb import MediaType, play_stream\n",
    "\n",
    "image = conn.upload(url=\"https://raw.githubusercontent.com/video-db/videodb-cookbook/dev/images/chase_trailer.png\", media_type=MediaType.image)\n",
    "\n",
    "image_asset = ImageAsset(\n",
    "    asset_id=image.id,\n",
    "    width=1392,\n",
    "    height=783,\n",
    "    x=0,\n",
    "    y=0,\n",
    "    duration=13\n",
    ")\n",
    "\n",
    "timeline.add_overlay(start=67.5, asset=image_asset)\n",
    "\n",
    "stream_url = timeline.generate_stream()\n",
    "play_stream(stream_url)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### üéâ Conclusion\n",
    "____\n",
    "Congratulations! You're about to dive into the exciting world of adding narration to trailers with VideoDB, OpenAI, and elevenlabs.io. Get ready to unleash your creativity and captivate audiences with thrilling trailers. Try out various narration styles and prompts to personalize your trailers and keep viewers hooked. Get excited about enhancing your trailers with AI-powered narration using VideoDB!\n",
    "\n",
    "For more such explorations, refer to the [VideoDB docs](https://docs.videodb.io/) and join the VideoDB community on [GitHub](https://github.com/video-db) or [Discord](https://discord.com/invite/py9P639jGz) for support and collaboration.\n",
    "\n",
    "We're excited to see your creations, so we welcome you to share your creations via [Discord](https://discord.com/invite/py9P639jGz), [LinkedIn](https://www.linkedin.com/company/videodb) or [Twitter](https://twitter.com/videodb_io).\n",
    "\n",
    "\n",
    "In the meanwhile, check out the other exciting outputs generated using this tutorial and share yours in our [community](https://discord.com/invite/py9P639jGz) too! We‚Äôd love to feature you here ‚ö°Ô∏è"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
