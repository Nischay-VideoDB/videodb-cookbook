{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# üîä AI Generated Ad Films for Product Videography"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a href=\"https://colab.research.google.com/github/video-db/videodb-cookbook/blob/main/examples/Wellsaid_Voiceover.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Overview"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Crafting AI content and blending results from multiple tools can be incredibly powerful and time-efficient. Manual execution of these tasks is often cumbersome and time-consuming. However, with the right tools and techniques, you can automate various processes to achieve remarkable results effortlessly.\n",
    "\n",
    "In this tutorial, we will explore how to leverage the seamless integration between `Wellsaid`, `OpenAI` and `VideoDB` to create captivating voiceovers for product advertisements. By harnessing the advanced capabilities of these platforms, you can enhance the storytelling and engagement of your product videos with AI-generated voiceovers; all within a single environment. \n",
    "\n",
    "For this tutorial, we‚Äôll be using a product footage from Youtube üëâüèº https://www.youtube.com/watch?v=2DcAMbmmYNM and convert it into a professionally made advertisement for a jewellery brand; all using AI and programmatic scripting & editing."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](https://raw.githubusercontent.com/video-db/videodb-cookbook-assets/main/images/examples/Wellsaid_Voiceover_1.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### üì¶  Installing packages "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ensure you have the necessary packages installed:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install openai\n",
    "%pip install videodb"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### üîë API Keys"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ensure you have access to [OpenAI](https://openai.com), [Wellsaid](https://wellsaidlabs.com/features/api/) and [VideoDB](https://videodb.io) API keys. If you haven't already, sign up for API access on the respective platforms.\n",
    "\n",
    "> Get your API key from [VideoDB Console](https://console.videodb.io). ( Free for first 50 uploads, **No credit card required** ) üéâ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "os.environ[\"OPENAI_API_KEY\"] = \"\"\n",
    "os.environ[\"WELLSAID_API_KEY\"] = \"\"\n",
    "os.environ[\"VIDEO_DB_API_KEY\"] = \"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### üéôÔ∏è  Wellsaid's Voice Avatar "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "You will also need Wellsaid's Voice Avatar that you want to use to generate your voiceover. \n",
    "\n",
    "For this demo, we‚Äôll choose a slick, professional ads voiceover artist‚Äôs voice. Wellsaid has a wide range of options to choose from- you can check them out by signing up on their platform and accessing their [Voice Studio](https://docs.wellsaidlabs.com/reference/available-voice-avatars). Once finalized, copy the Speaker ID from Wellsaid and link it here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "speaker_id = \"109\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Implementation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "### üåê Step 1: Connect to VideoDB\n",
    "Begin by establishing a connection to VideoDB using your API key"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from videodb import connect\n",
    "\n",
    "# Connect to VideoDB using your API key\n",
    "conn = connect()\n",
    "coll = conn.get_collection()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### üé• Step 2: Upload Video\n",
    "\n",
    "Upload your product video to VideoDB using its URL or file path."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Upload a video by URL (replace the url with your video)\n",
    "video = conn.upload(url='https://www.youtube.com/watch?v=2DcAMbmmYNM')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### üîç Step 3: Analyze Scenes and Generate Scene Descriptions\n",
    "\n",
    "Start by analyzing the scenes within your Video using VideoDB's scene indexing capabilities. This will provide context for the script prompt."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "video.index_scenes()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's view the description of first scene of the video"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 - 0.5338666666666667\n",
      "The image presented is overwhelmingly dark, with different shades of black and deep blues blending into each other. There are no discernible objects, figures, or distinct shapes to provide context or detail. The top right corner holds a small watermark or icon with illegible text, suggesting some form of branding or ownership. This image conveys a sense of emptiness or perhaps an abstract concept, as it lacks visual content that would normally inform the viewer's interpretation. It could represent a darkroom, outer space, or even an image error. The nature of this image is enigmatic and open-ended, allowing for various interpretations.\n"
     ]
    }
   ],
   "source": [
    "scenes = video.get_scenes()\n",
    "print(f\"{scenes[0]['start']} - {scenes[0]['end']}\")\n",
    "print(scenes[0][\"response\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 4: Generate Voiceover Script with LLM\n",
    "Combine scene descriptions with a script prompt, instructing LLM (OpenAI) to create a suitable voiceover for your product advertisement.\n",
    "\n",
    "This script prompt can be refined and tweaked to generate the most suitable output. Check out [these examples](https://www.youtube.com/playlist?list=PLhxAMFLSSK03rsPTjRv1LbAXHQpNN6BS0) to explore more use cases."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import openai\n",
    "\n",
    "client = openai.OpenAI()\n",
    "\n",
    "script_prompt = \"Here's the data from a scene index for a video from a jewellery product photoshoot. Study this and then generate a synced script based on the description below. Make sure the script is in the language, voice and style of a professional voiceover artist skilled at weaving beautiful storytelling in advertisements.\\n \\n\"\n",
    "\n",
    "full_prompt = script_prompt + \"\\n\\n\"\n",
    "for scene in scenes:\n",
    "  full_prompt += f\"- {scene}\\n\"\n",
    "\n",
    "openai_res = client.chat.completions.create(\n",
    "    model=\"gpt-3.5-turbo\",\n",
    "    messages=[{\"role\": \"system\", \"content\": full_prompt}],\n",
    ")\n",
    "voiceover_script = openai_res.choices[0].message.content\n",
    "\n",
    "\n",
    "# Truncate first 1000 characters of script\n",
    "# If you have Wellsaid's paid plan remove this\n",
    "voiceover_script = voiceover_script[:1000]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### üé§ Step 5: Generate Voiceover Audio with Wellsaid "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Utilize the generated script to synthesize a professional voiceover for your product advertisement using Wellsaid's API."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import time \n",
    "\n",
    "\n",
    "# Call Wellsaid API to generate voiceover\n",
    "url = \"https://api.wellsaidlabs.com/v1/tts/stream\"\n",
    "headers = {\n",
    "    \"accept\": \"application/json\",\n",
    "    \"content-type\": \"application/json\",\n",
    "    \"X-Api-Key\": os.environ.get(\"WELLSAID_API_KEY\")\n",
    "}\n",
    "\n",
    "# Initiate TTS Job for each Chunk\n",
    "payload = {\n",
    "    \"text\": voiceover_script,\n",
    "    \"speaker_id\": speaker_id\n",
    "}\n",
    "wellsaid_res = requests.request(\"POST\", url, json=payload, headers=headers)\n",
    "\n",
    "# Save the audio file\n",
    "audio_file = \"audio.mp3\"\n",
    "CHUNK_SIZE = 1024\n",
    "with open(audio_file, 'wb') as f:\n",
    "    for chunk in wellsaid_res.iter_content(chunk_size=CHUNK_SIZE):\n",
    "        if chunk:\n",
    "            f.write(chunk)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### üé¨ Step 6: Add Voiceover to Video with VideoDB"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In order to use the voiceover generated above, let's upload the audio file (voiceover) to VideoDB first"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "audio = conn.upload(file_path=audio_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, add the AI-generated voiceover to the original footage using VideoDB's [timeline feature](https://docs.videodb.io/version-0-0-3-timeline-and-assets-44)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from videodb.timeline import Timeline\n",
    "from videodb.asset import VideoAsset, AudioAsset\n",
    "\n",
    "# Create a timeline object\n",
    "timeline = Timeline(conn)\n",
    "\n",
    "# Add the video asset to the timeline for playback\n",
    "video_asset = VideoAsset(asset_id=video.id)\n",
    "timeline.add_inline(asset=video_asset)\n",
    "\n",
    "# Add the audio asset to the timeline for playback\n",
    "audio_asset = AudioAsset(asset_id=audio.id)\n",
    "timeline.add_overlay(start=0, asset=audio_asset)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ü™Ñ Step 7: Review and Share\n",
    "\n",
    "Preview the product video with the integrated voiceover to ensure it aligns with your vision. Once satisfied, share the video to showcase your product effectively.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from videodb import play_stream\n",
    "\n",
    "stream_url = timeline.generate_stream()\n",
    "play_stream(stream_url)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### üéâ Conclusion:\n",
    "Congratulations! You have successfully automated the process of creating AI-generated voiceovers for product videography using Wellsaid and VideoDB.\n",
    "\n",
    "Experiment with different script prompts and scene analysis techniques to tailor the voiceovers to your specific product and audience. We look forward to seeing your captivating product videos!\n",
    "\n",
    "For more such explorations, refer to the [documentation of VideoDB](https://docs.videodb.io/) and join the VideoDB community on [GitHub](https://github.com/video-db) or [Discord](https://discord.com/invite/py9P639jGz) for support and collaboration.\n",
    "\n",
    "We're excited to see your creations, so we welcome you to share your creations via [Discord](https://discord.com/invite/py9P639jGz), [LinkedIn](https://www.linkedin.com/company/videodb) or [Twitter](https://twitter.com/videodb_io)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
