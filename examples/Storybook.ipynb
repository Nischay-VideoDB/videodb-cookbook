{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# StoryBoard"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a href=\"https://colab.research.google.com/github/video-db/videodb-cookbook/blob/nb/storybook/examples/Storybook.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Installing the required packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: videodb in /Users/rohit/Spext/videodb/videodb-cookbook/.venv/lib/python3.11/site-packages (0.1.0)\n",
      "Requirement already satisfied: openai in /Users/rohit/Spext/videodb/videodb-cookbook/.venv/lib/python3.11/site-packages (1.13.3)\n",
      "Requirement already satisfied: requests>=2.25.1 in /Users/rohit/Spext/videodb/videodb-cookbook/.venv/lib/python3.11/site-packages (from videodb) (2.31.0)\n",
      "Requirement already satisfied: backoff>=2.2.1 in /Users/rohit/Spext/videodb/videodb-cookbook/.venv/lib/python3.11/site-packages (from videodb) (2.2.1)\n",
      "Requirement already satisfied: tqdm>=4.66.1 in /Users/rohit/Spext/videodb/videodb-cookbook/.venv/lib/python3.11/site-packages (from videodb) (4.66.2)\n",
      "Requirement already satisfied: anyio<5,>=3.5.0 in /Users/rohit/Spext/videodb/videodb-cookbook/.venv/lib/python3.11/site-packages (from openai) (4.3.0)\n",
      "Requirement already satisfied: distro<2,>=1.7.0 in /Users/rohit/Spext/videodb/videodb-cookbook/.venv/lib/python3.11/site-packages (from openai) (1.9.0)\n",
      "Requirement already satisfied: httpx<1,>=0.23.0 in /Users/rohit/Spext/videodb/videodb-cookbook/.venv/lib/python3.11/site-packages (from openai) (0.27.0)\n",
      "Requirement already satisfied: pydantic<3,>=1.9.0 in /Users/rohit/Spext/videodb/videodb-cookbook/.venv/lib/python3.11/site-packages (from openai) (2.6.3)\n",
      "Requirement already satisfied: sniffio in /Users/rohit/Spext/videodb/videodb-cookbook/.venv/lib/python3.11/site-packages (from openai) (1.3.1)\n",
      "Requirement already satisfied: typing-extensions<5,>=4.7 in /Users/rohit/Spext/videodb/videodb-cookbook/.venv/lib/python3.11/site-packages (from openai) (4.10.0)\n",
      "Requirement already satisfied: idna>=2.8 in /Users/rohit/Spext/videodb/videodb-cookbook/.venv/lib/python3.11/site-packages (from anyio<5,>=3.5.0->openai) (3.6)\n",
      "Requirement already satisfied: certifi in /Users/rohit/Spext/videodb/videodb-cookbook/.venv/lib/python3.11/site-packages (from httpx<1,>=0.23.0->openai) (2024.2.2)\n",
      "Requirement already satisfied: httpcore==1.* in /Users/rohit/Spext/videodb/videodb-cookbook/.venv/lib/python3.11/site-packages (from httpx<1,>=0.23.0->openai) (1.0.4)\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in /Users/rohit/Spext/videodb/videodb-cookbook/.venv/lib/python3.11/site-packages (from httpcore==1.*->httpx<1,>=0.23.0->openai) (0.14.0)\n",
      "Requirement already satisfied: annotated-types>=0.4.0 in /Users/rohit/Spext/videodb/videodb-cookbook/.venv/lib/python3.11/site-packages (from pydantic<3,>=1.9.0->openai) (0.6.0)\n",
      "Requirement already satisfied: pydantic-core==2.16.3 in /Users/rohit/Spext/videodb/videodb-cookbook/.venv/lib/python3.11/site-packages (from pydantic<3,>=1.9.0->openai) (2.16.3)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /Users/rohit/Spext/videodb/videodb-cookbook/.venv/lib/python3.11/site-packages (from requests>=2.25.1->videodb) (3.3.2)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /Users/rohit/Spext/videodb/videodb-cookbook/.venv/lib/python3.11/site-packages (from requests>=2.25.1->videodb) (2.2.1)\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.2.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m24.0\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install videodb openai"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### API keys\n",
    "\n",
    "Before proceeding, ensure access to [VideoDB](https://videodb.io), [OpenAI](https://openai.com), and [ElevenLabs](https://elevenlabs.io) API key. If not, sign up for API access on the respective platforms.\n",
    "\n",
    "> You can get VideoDB's API key from üëâüèº [VideoDB Console](https://console.videodb.io). ( Free for first 50 uploads, **No credit card required!** )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "os.environ[\"OPENAI_API_KEY\"] = \"\"\n",
    "os.environ[\"ELEVEN_LABS_API_KEY\"] = \"\"\n",
    "os.environ[\"VIDEO_DB_API_KEY\"] = \"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ElevenLab's Voice ID \n",
    "\n",
    "You will also need ElevenLab's VoiceID of a Voice that you want to use.\n",
    "\n",
    "Please add [this](https://elevenlabs.io/app/voice-lab/share/eea2654def1e6c5bda5b4ce8f99f8f2c857b71a15cd6188c27d337206ea98177/s6sJbrmNIsT6M7vdjjES) Voice to Your VoiceLab and copy VoiceID from there.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "voiceover_artist_id = \"l0CzJ3s4XFnGAHKDinPf\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Setup VideoDB Connection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from videodb import connect\n",
    "\n",
    "conn = connect()\n",
    "coll = conn.get_collection()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define Your App"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "app_description = \"A meditation app for busy people with anxiety.\"\n",
    "raw_steps= [\n",
    "    \"Set up profile\",\n",
    "    \"Select preference for theme & music\",\n",
    "    \"Set meditation session timing\",\n",
    "    \"Start the session\"\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating Assets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prompts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prompt_voiceover_scripts(steps, app_description):\n",
    "    prompt = f\"Generate a structured response for {app_description}. in the user journey. This description should capture the essence of the action performed by the user during this step. This application aims to {app_description}. Here are the steps involved in the user journey, Elaborate the each step and involved the specifc steps requird in the stage:\"\n",
    "    for step in steps:\n",
    "        prompt += f\"\"\"\\n- \n",
    "        Create a concise description for the step '{step['step']}' in the user journey. This description should capture the essence of the action performed by the user during this step.\n",
    "        Create a conversational and engaging script for an app where the user is {step['step']}. \n",
    "        Keep it narrative-driven, within two sentences.\n",
    "        \"\"\"\n",
    "    prompt += \"\"\"Return a response in json fromat, with key 'steps', and value being a list of dicts, where each dict has two keys 'step_description' and 'voiceover_script'\n",
    "    {\n",
    "        steps: [ \n",
    "        {\n",
    "        'step_description': 'A concise description for the step',\n",
    "        'voiceover_script': 'A conversational and engaging script for the step. Keep it narrative-driven, within two sentences.'\n",
    "        }\n",
    "        ]\n",
    "    }\n",
    "    \"\"\"\n",
    "    return prompt\n",
    "\n",
    "\n",
    "def prompt_image_genration(step, app_description):\n",
    "    return f\"\"\"\n",
    "    Create an illustration in a simple and minimalist, duotone style, pink and black, with pastel colours and a single central character of a woman with short hair. \n",
    "    Restrict the use of text and keep the illustration as a simple line art with minimal elements\n",
    "    This illustration is a part of a storyboard to explain the user journey of an app built for {app_description}. \n",
    "    This image will portray the '{step['step']}' stage in the app.Step description: {step['step_description']}. \n",
    "    This illustration is meant for professional storyboarding, so understand the requirements accordingly and create a suitable illustration\n",
    "    \"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def payload_voiceover_script(api_key, script):\n",
    "    headers = {\"xi-api-key\": api_key, \"Content-Type\": \"application/json\"}\n",
    "    payload = {\n",
    "        \"model_id\": \"eleven_monolingual_v1\",\n",
    "        \"text\": script,\n",
    "        \"voice_settings\": {\"stability\": 0.5, \"similarity_boost\": 0.5},\n",
    "    }\n",
    "    return headers, payload"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Voiceover Scripts & Step Descriptions - OpenAI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import openai\n",
    "import json\n",
    "\n",
    "\n",
    "def generate_voiceover_scripts(steps):\n",
    "    print(\"\\nGenerating Voiceover script and Step Description...\")\n",
    "    client = openai.OpenAI()\n",
    "    prompt = prompt_voiceover_scripts(steps, app_description)\n",
    "    openai_res = client.chat.completions.create(\n",
    "        model=\"gpt-3.5-turbo\",\n",
    "        messages=[{\"role\": \"system\", \"content\": prompt}],\n",
    "        response_format={\"type\": \"json_object\"},\n",
    "    )\n",
    "\n",
    "    openai_res = json.loads(openai_res.choices[0].message.content)\n",
    "    return openai_res[\"steps\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Voiceover Audio Generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "\n",
    "\n",
    "def generate_voiceover_audio(script, file):\n",
    "    print(\"\\nConverting Voiceover Script to Audio...\")\n",
    "    url = f\"https://api.elevenlabs.io/v1/text-to-speech/{voiceover_artist_id}\"\n",
    "    try:\n",
    "        headers, payload = payload_voiceover_script(\n",
    "            os.environ.get(\"ELEVEN_LABS_API_KEY\"), script\n",
    "        )\n",
    "        elevenlabs_res = requests.request(\"POST\", url, json=payload, headers=headers)\n",
    "        elevenlabs_res.raise_for_status()\n",
    "        # Save the audio file\n",
    "        with open(file, \"wb\") as f:\n",
    "            f.write(elevenlabs_res.content)\n",
    "        print(f\"Result : voiceover audio saved as {file}\")\n",
    "    except Exception as e:\n",
    "        print(\"An Error coccured while converting the voiceover script to audio: \", e)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Image Generation - Dalle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_image_dalle(step, app_description):\n",
    "    print(\"\\nGenerating Image...\")\n",
    "    prompt = prompt_image_genration(step, app_description)\n",
    "    try:\n",
    "        client = openai.Client()\n",
    "        response = client.images.generate(\n",
    "            model=\"dall-e-3\", prompt=prompt, n=1, size=\"1024x1024\"\n",
    "        )\n",
    "        print(\"Result : \", response.data[0].url)\n",
    "        return response.data[0].url\n",
    "    except Exception as e:\n",
    "        print(f\"An error occurred while generating the image: {e}\")\n",
    "        return None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generating Assets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_user_journey(steps, app_description):\n",
    "    print(\"App Description:\", app_description)\n",
    "\n",
    "    step_scripts = generate_voiceover_scripts(steps)\n",
    "    for index, step in enumerate(step_scripts):\n",
    "        steps[index][\"step_description\"] = step[\"step_description\"]\n",
    "        steps[index][\"voiceover_script\"] = step[\"voiceover_script\"]\n",
    "\n",
    "    for index, step in enumerate(steps):\n",
    "        print(f\"\\n---------------------- \\nProcessing step: {step['step']}\")\n",
    "\n",
    "        voiceover_script = step[\"voiceover_script\"]\n",
    "        if voiceover_script:\n",
    "            voiceover_file_name = f\"voiceover_{index}.mp3\"\n",
    "            step[\"voiceover_filename\"] = voiceover_file_name\n",
    "            generate_voiceover_audio(voiceover_script, voiceover_file_name)\n",
    "        image_url = generate_image_dalle(step, app_description)\n",
    "        if image_url:\n",
    "            step[\"image_url\"] = image_url"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "App Description: A meditation app for busy people with anxiety.\n",
      "\n",
      "Generating Voiceover script and Step Description...\n",
      "\n",
      "---------------------- \n",
      "Processing step: Set up profile\n",
      "\n",
      "Converting Voiceover Script to Audio...\n",
      "Result : voiceover audio saved as voiceover_0.mp3\n",
      "\n",
      "Generating Image...\n",
      "Result :  https://oaidalleapiprodscus.blob.core.windows.net/private/org-map9J6yCG74QUls8JLyE2N7r/user-kqCy428rS4ZPTYHJCYV6HouY/img-sHfM9Sf1GYuVYarRy81NNdyI.png?st=2024-04-25T17%3A53%3A07Z&se=2024-04-25T19%3A53%3A07Z&sp=r&sv=2021-08-06&sr=b&rscd=inline&rsct=image/png&skoid=6aaadede-4fb3-4698-a8f6-684d7786b067&sktid=a48cca56-e6da-484e-a814-9c849652bcb3&skt=2024-04-24T19%3A11%3A46Z&ske=2024-04-25T19%3A11%3A46Z&sks=b&skv=2021-08-06&sig=2WEuMP02c2gAQ7DYITrIEuxlULOyL67WJIP9eCBLOKM%3D\n",
      "\n",
      "---------------------- \n",
      "Processing step: Select preference for theme & music\n",
      "\n",
      "Converting Voiceover Script to Audio...\n",
      "Result : voiceover audio saved as voiceover_1.mp3\n",
      "\n",
      "Generating Image...\n",
      "Result :  https://oaidalleapiprodscus.blob.core.windows.net/private/org-map9J6yCG74QUls8JLyE2N7r/user-kqCy428rS4ZPTYHJCYV6HouY/img-ztEehCiYaU0nPYpEN5wsYGsT.png?st=2024-04-25T17%3A53%3A33Z&se=2024-04-25T19%3A53%3A33Z&sp=r&sv=2021-08-06&sr=b&rscd=inline&rsct=image/png&skoid=6aaadede-4fb3-4698-a8f6-684d7786b067&sktid=a48cca56-e6da-484e-a814-9c849652bcb3&skt=2024-04-25T15%3A49%3A02Z&ske=2024-04-26T15%3A49%3A02Z&sks=b&skv=2021-08-06&sig=%2BPaGAFvrE%2Bi7IbVAjNbKqlAfT9EpgygqYSyLXgTp/4E%3D\n",
      "\n",
      "---------------------- \n",
      "Processing step: Set meditation session timing\n",
      "\n",
      "Converting Voiceover Script to Audio...\n",
      "Result : voiceover audio saved as voiceover_2.mp3\n",
      "\n",
      "Generating Image...\n",
      "Result :  https://oaidalleapiprodscus.blob.core.windows.net/private/org-map9J6yCG74QUls8JLyE2N7r/user-kqCy428rS4ZPTYHJCYV6HouY/img-w80c5OA1jQbAHE47uOCLrlim.png?st=2024-04-25T17%3A53%3A53Z&se=2024-04-25T19%3A53%3A53Z&sp=r&sv=2021-08-06&sr=b&rscd=inline&rsct=image/png&skoid=6aaadede-4fb3-4698-a8f6-684d7786b067&sktid=a48cca56-e6da-484e-a814-9c849652bcb3&skt=2024-04-25T15%3A54%3A11Z&ske=2024-04-26T15%3A54%3A11Z&sks=b&skv=2021-08-06&sig=Frbnlyc6dvTmqDhipqD8jzTa8SM9T9e4sWvwIB2xVqI%3D\n",
      "\n",
      "---------------------- \n",
      "Processing step: Start the session\n",
      "\n",
      "Converting Voiceover Script to Audio...\n",
      "Result : voiceover audio saved as voiceover_3.mp3\n",
      "\n",
      "Generating Image...\n",
      "Result :  https://oaidalleapiprodscus.blob.core.windows.net/private/org-map9J6yCG74QUls8JLyE2N7r/user-kqCy428rS4ZPTYHJCYV6HouY/img-HXjYgxm3tRKrlaH5BGk8T0ls.png?st=2024-04-25T17%3A54%3A13Z&se=2024-04-25T19%3A54%3A13Z&sp=r&sv=2021-08-06&sr=b&rscd=inline&rsct=image/png&skoid=6aaadede-4fb3-4698-a8f6-684d7786b067&sktid=a48cca56-e6da-484e-a814-9c849652bcb3&skt=2024-04-24T19%3A15%3A17Z&ske=2024-04-25T19%3A15%3A17Z&sks=b&skv=2021-08-06&sig=Uwez3QsMGE7Pol3xlqKIwYGNXRMG/YkDm3MJit9NMm0%3D\n"
     ]
    }
   ],
   "source": [
    "steps = []\n",
    "for app_step in raw_steps:\n",
    "    steps.append({\"step\": app_step})\n",
    "process_user_journey(steps, app_description)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Putting it All Together "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Upload Assets to VideoDB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "----------------------\n",
      "Processing step: Set up profile\n",
      "\n",
      "Uploading Image...\n",
      "Uploaded Image\n",
      "\n",
      "Uploading Voiceover Audio...\n",
      "Uploaded Voiceover Audio\n",
      "\n",
      "----------------------\n",
      "Processing step: Select preference for theme & music\n",
      "\n",
      "Uploading Image...\n",
      "Uploaded Image\n",
      "\n",
      "Uploading Voiceover Audio...\n",
      "Uploaded Voiceover Audio\n",
      "\n",
      "----------------------\n",
      "Processing step: Set meditation session timing\n",
      "\n",
      "Uploading Image...\n",
      "Uploaded Image\n",
      "\n",
      "Uploading Voiceover Audio...\n",
      "Uploaded Voiceover Audio\n",
      "\n",
      "----------------------\n",
      "Processing step: Start the session\n",
      "\n",
      "Uploading Image...\n",
      "Uploaded Image\n",
      "\n",
      "Uploading Voiceover Audio...\n",
      "Uploaded Voiceover Audio\n"
     ]
    }
   ],
   "source": [
    "from videodb import MediaType\n",
    "\n",
    "for step in steps:\n",
    "    print(f\"\"\"\\n----------------------\\nProcessing step: {step['step']}\"\"\")\n",
    "\n",
    "    print(\"\\nUploading Image...\")\n",
    "    image = coll.upload(url=step[\"image_url\"], media_type=MediaType.image)\n",
    "    print(\"Uploaded Image\")\n",
    "\n",
    "    print(\"\\nUploading Voiceover Audio...\")\n",
    "    audio = coll.upload(file_path=step[\"voiceover_filename\"])\n",
    "    print(\"Uploaded Voiceover Audio\")\n",
    "\n",
    "    step[\"image_id\"] = image.id\n",
    "    step[\"audio_id\"] = audio.id"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating Timeline in VideoDB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from videodb.asset import VideoAsset, ImageAsset, AudioAsset\n",
    "from videodb.timeline import Timeline\n",
    "from videodb import play_stream\n",
    "\n",
    "timeline = Timeline(conn)\n",
    "\n",
    "seeker = 0\n",
    "\n",
    "# Create Asset for Image and Audio Asset\n",
    "for step in steps:\n",
    "    audio = coll.get_audio(step[\"audio_id\"])\n",
    "    image = coll.get_image(step[\"image_id\"])\n",
    "\n",
    "    audio_duration = float(audio.length)\n",
    "\n",
    "    image_asset = ImageAsset(\n",
    "        image.id, duration=audio_duration, x=100, y=0, width=1080, height=720\n",
    "    )\n",
    "    audio_asset = AudioAsset(audio.id, disable_other_tracks=True)\n",
    "\n",
    "    timeline.add_overlay(seeker, audio_asset)\n",
    "    timeline.add_overlay(seeker, image_asset)\n",
    "\n",
    "    seeker += audio_duration\n",
    "\n",
    "# Upload a base Video, that will be used as a background\n",
    "base_vid = coll.upload(url=\"https://www.youtube.com/watch?v=4dW1ybhA5bM\")\n",
    "base_vid_aset = VideoAsset(base_vid.id, end=seeker)\n",
    "timeline.add_inline(base_vid_aset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'https://console.videodb.io/player?url=https://dseetlpshk2tb.cloudfront.net/v3/published/manifests/c736d4fb-af30-4e9b-94ab-c0528e8482d8.m3u8'"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stream_url = timeline.generate_stream()\n",
    "play_stream(stream_url)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
