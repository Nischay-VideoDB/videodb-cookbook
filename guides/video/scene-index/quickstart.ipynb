{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ‚ö°Ô∏è QuickStart: Scene Index"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a href=\"https://colab.research.google.com/github/video-db/videodb-cookbook/blob/main/guides/video/scene-index/quickstart.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This guide gives you an introduction to Scene Indexing. \n",
    "\n",
    "The versatility of scene indexing opens up a world of possibilities for finding visual information in videos. Advanced vision models empower us with unprecedented control over the extraction of information from videos. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### üì¶  Installing packages   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install videodb"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### üîë API Keys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "os.environ[\"VIDEO_DB_API_KEY\"] = \"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### üåê Connect to VideoDB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from videodb import connect\n",
    "\n",
    "conn = connect()\n",
    "coll = conn.get_collection()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### üé•  Upload Video"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "video = coll.upload(url=\"https://www.youtube.com/watch?v=LejnTJL173Y\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üìá Index Scenes \n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In just one command, the `index_scenes` function can index visual information in your video."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "index_id = video.index_scenes()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`index_scenes()` has many optional parameters. You can use different `extraction algorithms` to select scene and frames.  \n",
    "Additionally, you can use `prompts` to describe these scenes and frames using a vision model. Read more about [Scene and Frame object](https://github.com/video-db/videodb-cookbook/blob/main/guides/video/scene-index/advanced_visual_search.ipynb)\n",
    "\n",
    ">Currently this index is well suited for **semantic search** so try have your prompts designed to output **well written prose** that can be indexed well for semantic search. \n",
    ">\n",
    ">üòé Soon we are going to support json and sql data extraction and indexing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from videodb import SceneExtractionType, IndexType\n",
    "\n",
    "index_id = video.index_scenes(\n",
    "    extraction_type=SceneExtractionType.time_based,\n",
    "    extraction_config={\"time\":10, \"select_frames\": ['first']},\n",
    "    prompt=\"describe the image in 100 words\",\n",
    "    # callback_url=callback_url,\n",
    ")\n",
    "\n",
    "# Wait to Indexing to finish\n",
    "scene_index = video.get_scene_index(index_id)\n",
    "print(scene_index)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Note: it might take a additional 5-10 seconds for your index to become available for search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Once the indexing is done, you can start search over your video library. \n",
    "# Default : search all indexes \n",
    "res = video.search(query=\"drinking\", index_type=IndexType.scene, index_id=index_id)\n",
    "res.play()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ‚öôÔ∏è Index Scenes Parameters \n",
    "---\n",
    "\n",
    ">**`index_scenes` parameters**:\n",
    ">\n",
    "> - `extraction_type`  - Choose scene extraction algorithm.\n",
    ">\n",
    "> - `extraction_config`  - Configuration of scene extraction algorithm.\n",
    ">\n",
    "> - `prompt` - Prompt to describe each scene in text.\n",
    ">\n",
    "> - `callback_url` - Notification url when the job is done.\n",
    "\n",
    "Let‚Äôs go in detail of each parameter for this function "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ‚öôÔ∏è `extraction_type` & `extraction_config`\n",
    "\n",
    "Visually, a video is a series of images. A 60fps video, for instance, has 60 frames per second and feels high in quality compared to a 30fps video. With extraction_type, we can experiment with the frame extraction algorithms.\n",
    "\n",
    "We don‚Äôt have to send each frame to the vision model, as that would turn out to be inefficient and costly. \n",
    "\n",
    "*We first present the simplest way to sample frames. Choose a lower frequency than the fps of videoüëá*\n",
    "\n",
    "**‚öôÔ∏è Time-Based Extraction**\n",
    "\n",
    "First, you need to set `extraction_type` to `SceneExtractionType.time_based`  \n",
    "Then to configure, you can pass a Python Dict to the `extraction_config` argument with following keys.\n",
    "\n",
    "* `time`: Specifies the interval (in seconds) at which scenes are segmented. Default value is `10` - Every 10sec is a scene.\n",
    "* `select_frames`: A list of frames to select from each segment. The list can contain strings from the following: `\"first\"`, `\"middle\"`, or `\"last\"`, which selects the respective frames. Default value is `[\"first\"]`\n",
    "\n",
    ">Note: This algorithm may not perform well with static videos. We can develop more advanced methods to segment videos into a few scenes and frames. One such method is based on shot detection üëá\n",
    "<br>\n",
    "\n",
    "\n",
    "**‚öôÔ∏è Shot-Based Extraction**\n",
    "Videos share context between timestamps. A scene is a logical segment of a video that completes a concept. There are many ways to describe a scene. One way is to identify scene changes based on visual content within the video. Key factors are: <u>significant changes in the visual content</u>, such as **transitions, lighting changes, and movement**.\n",
    "\n",
    "First, you need to set `extraction_type` to `SceneExtractionType.time_based`  \n",
    "To configure, you can pass a Python Dict to the `extraction_config` argument with following keys.\n",
    "\n",
    "* `threshold`: Determines the sensitivity of the model towards scene changes within the video. Default value is `20`, which known to be good for detecting camera shot changes from a video.\n",
    "* `frame_count`: Accepts a number that specifies how many frames to pick from each shot. Default value is `1` Increasing this number will result in more frames being selected from each shot, which could provide a more detailed analysis of the scene.  \n",
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ô∏è‚öôÔ∏è `prompt`\n",
    "\n",
    "VideoDB seamlessly integrates with all vision models. Use the following prompt to describe each scene:\n",
    "\n",
    "`‚ÄúDescribe clearly what is happening in the video. Add running_detected if you see a person running.‚Äù` \n",
    "\n",
    "This prompt is sent to the vision models. If you are interested in experimenting with your own model, check out our guide on [Advanced Visual Search Pipelines](https://github.com/video-db/videodb-cookbook/blob/main/guides/video/scene-index/advanced_visual_search.ipynb)\n",
    "\n",
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ‚öôÔ∏è `callback_url`\n",
    "\n",
    "URL to send notification when the scene index process is completed.\n",
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ">We offer an open pipeline where you can experiment in detail with extraction algorithms and prompts.   \n",
    ">\n",
    ">Check out the following:\n",
    ">\n",
    ">- [Playground for Scene Extractions](https://github.com/video-db/videodb-cookbook/blob/main/guides/video/scene-index/playground_scene_extraction.ipynb)\n",
    ">\n",
    ">- [Advanced Visual Search Pipelines](https://github.com/video-db/videodb-cookbook/blob/main/guides/video/scene-index/advanced_visual_search.ipynb)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üóÇÔ∏è Managing Indexes\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ">  \n",
    "> üí° You can create multiple scene indexes for a video and rank the results after a search before presenting them to your user."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**List all scene Indexes created on a video**:\n",
    "\n",
    "`Video.list_scene_index()` will return list of available scene indexes with `id` and `status` "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scene_indexes = video.list_scene_index()\n",
    "print(scene_indexes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Get Specific Index:**  \n",
    "\n",
    "`Video.get_scene_index()` will return list of indexed scenes with `scene_index_id`, `start`, `end` and `description`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scene_index = video.get_scene_index(index_id) \n",
    "print(scene_index)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Delete a index:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "video.delete_scene_index(index_id)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üßë‚Äçüíª Deep Dive\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "Check out the other resources and tutorials using Scene Indexing\n",
    "* If you want to bring your own scene descriptions and annotations, explore the [Custom Annotations  Pipeline](https://github.com/video-db/videodb-cookbook/blob/main/guides/video/scene-index/custom_annotations.ipynb)\n",
    "* Experiment with extraction algorithms, prompts, and search using the [Playground for Scene Extractions](https://github.com/video-db/videodb-cookbook/blob/main/guides/video/scene-index/playground_scene_extraction.ipynb)\n",
    "* Check out our open and flexible [Advanced Visual Search Pipelines](https://github.com/video-db/videodb-cookbook/blob/main/guides/video/scene-index/advanced_visual_search.ipynb)\n",
    "\n",
    "\n",
    "If you have any questions or feedback. Feel free to reach out to us üôåüèº\n",
    "\n",
    "* [Discord](https://colab.research.google.com/corgiredirector?site=https%3A%2F%2Fdiscord.gg%2Fpy9P639jGz)\n",
    "* [GitHub](https://github.com/video-db)\n",
    "* [VideoDB](https://colab.research.google.com/corgiredirector?site=https%3A%2F%2Fvideodb.io)\n",
    "* [Email](ashu@videodb.io)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
