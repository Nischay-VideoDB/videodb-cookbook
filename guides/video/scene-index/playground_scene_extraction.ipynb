{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ‚úÇÔ∏èüé¨Ô∏è Scene Index: Scene Extraction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a href=\"https://colab.research.google.com/github/video-db/videodb-cookbook/blob/main/guides/video/scene-index/playground_scene_extraction.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> This guide assumes you are already familiar with the concept of Scene Indexing. If you are not, please refer to our [Scene Index: QuickStart](https://github.com/video-db/videodb-cookbook/blob/main/guides/video/scene-index/quickstart.ipynb) Guide to get up to speed.  \n",
    "\n",
    "Sometimes, it's important to determine the number of scenes needed to describe a video, as this can vary depending on the type of video. For instance, videos of a podcast with two hosts tend to be less dynamic than sports videos\n",
    "\n",
    "If you want to extract scenes from the video without indexing them, you can use the `Video.extract_scenes()` function. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### üì¶  Installing packages   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install videodb"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### üîë API Keys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "os.environ[\"VIDEO_DB_API_KEY\"] = \"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### üåê Connect to VideoDB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from videodb import connect\n",
    "\n",
    "conn = connect()\n",
    "coll = conn.get_collection()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### üé•  Upload Video"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "video = coll.upload(url=\"https://www.youtube.com/watch?v=LejnTJL173Y\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ‚úÇÔ∏èüé¨ Extracting Scenes without Indexing\n",
    "---\n",
    "\n",
    "`Video.extract_scenes()` extracts the frame skipping the indexing part, This function is useful if you want to experiment with the configuration of your Extract Scenes pipeline\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ‚öôÔ∏è Extract Scenes Parameters \n",
    "\n",
    "- `extraction_type`  - Choose a scene extraction algorithm.\n",
    "- `extraction_config`  - Configuration settings for the chosen scene extraction algorithm..\n",
    "\n",
    "\n",
    "Depending on your Scene Extraction pipeline, you will need to provide `extraction_config` according to the specific requirements of that pipeline.\n",
    "\n",
    "Let‚Äôs delve into the details of each pipeline and the respective configurations needed for them."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "### **‚öôÔ∏è Time-Based Extraction**\n",
    "\n",
    "First, you need to set `extraction_type` to `SceneExtractionType.time_based`    \n",
    "Then to configure, you can pass a Python Dict to the `extraction_config` argument with following keys.\n",
    "\n",
    "* `time`: Specifies the interval (in seconds) at which scenes are segmented. Default value is `10` - Every 10sec is a scene.\n",
    "* `select_frames`: A list of frames to select from each segment. The list can contain strings from the following: `\"first\"`, `\"middle\"`, or `\"last\"`, which selects the respective frames.   \n",
    "Default value is `[\"first\"]`\n",
    "\n",
    ">Note: This algorithm may not perform well with static videos. We can develop more advanced methods to segment videos into a few scenes and frames. One such method is based on shot detection üëá\n",
    "<br>\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from videodb import SceneExtractionType\n",
    "\n",
    "scene_collection_time = video.extract_scenes(\n",
    "    extraction_type=SceneExtractionType.time_based,\n",
    "    extraction_config={\"time\": 30, \"select_frames\": [\"first\", \"middle\", \"last\"]},\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **‚öôÔ∏è Shot-Based Extraction**  \n",
    "\n",
    "Videos share context between timestamps. A scene is a logical segment of a video that completes a concept. There are many ways to describe a scene. One way is to identify scene changes based on visual content within the video. Key factors are: <u>significant changes in the visual content</u>, such as **transitions, lighting changes, and movement**.\n",
    "\n",
    "First, you need to set `extraction_type` to `SceneExtractionType.time_based`.    \n",
    "To configure, you can pass a Python Dict to the `extraction_config` argument with following keys.\n",
    "\n",
    "* `threshold`: Determines the sensitivity of the model towards scene changes within the video. Default value is `20`, which known to be good for detecting camera shot changes from a video.\n",
    "* `frame_count`: Accepts a number that specifies how many frames to pick from each shot. Default value is `1` Increasing this number will result in more frames being selected from each shot, which could provide a more detailed analysis of the scene.  \n",
    "<br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from videodb import SceneExtractionType\n",
    "\n",
    "scene_collection_shot = video.extract_scenes(\n",
    "    extraction_type=SceneExtractionType.shot_based,\n",
    "    extraction_config={\"threshold\": 15, \"frame_count\": 5},\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Viewing, Inspecting, and Deleting Your SceneCollections\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For every scene extraction pipeline that you run on a video, a `SceneCollection` object is created.\n",
    "\n",
    "You can use following functions to View, Inspect and Delete your `SceneCollection`s"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Viewing all `SceneCollection`s for a Video**:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scene_collections = video.list_scene_collection()\n",
    "for scene_collection in scene_collections:\n",
    "    print(\"Scene Collection Id :\",scene_collection[\"scene_collection_id\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Get `SceneCollection` by ID**:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "first_coll_id = scene_collections[0][\"scene_collection_id\"]\n",
    "scene_collection = video.get_scene_collection(first_coll_id)\n",
    "\n",
    "print(\"This is Scene Collection\", scene_collection)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Inspecting `SceneCollection`**:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"This is scene collection id\", scene_collection_shot.id)\n",
    "print(\"This is scene collection config\", scene_collection_shot.config)\n",
    "scenes = scene_collection_shot.scenes\n",
    "for scene in scenes:\n",
    "    print(f\"Scene Duration {scene.start}-{scene.end}\")\n",
    "    for frame in scene.frames:\n",
    "        print(f\"- Frame at {frame.frame_time} {frame.url}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Delete a `SceneCollection`**:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "video.delete_scene_collection(scene_collection_shot.id)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ‚úçÔ∏è Playground: Play with Prompt\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before finalizing your prompt, consider experimenting with different ones. This will help you see how the search performs for your use cases. Start by iterating over only a few scenes. Then, experiment with your prompt and test it after indexing\n",
    "\n",
    "We believe that the right prompt is very helpful in finding information that aligns with your domain knowledge and experience.  For this we provide following describe functions at Frame and Scene level. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### `Frame.describe()`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "frame_prompt = \"\"\"\n",
    "You will be provided with an image. Your task is to identify and describe the objects in the image.\n",
    "1.\tIdentify Objects: List distinct objects in the image.\n",
    "2.\tDescribe Objects: Provide a brief description of each object, including shape, color, and any notable features.\n",
    "\n",
    "Ouput should be a list of objects\n",
    "Expected Output:\n",
    "[{\"name\": \"book\", \"context\": \"a person wearing a white shirt is holding a book\"}]\n",
    "\"\"\"\n",
    "\n",
    "# Fetch the first frame of the first scene\n",
    "frame = scene_collection_time.scenes[0].frames[0]\n",
    "\n",
    "# Describe the frame\n",
    "frame.describe(prompt=frame_prompt)\n",
    "\n",
    "print(frame)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### `Scene.Describe()`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scene_prompt = \"\"\"\n",
    "You will be provided with a series of images. Your task is to view all images together and describe the overall story or scene in the best possible way.\n",
    "\n",
    "Expected Output:\n",
    "- A detailed story or scene description.\n",
    "- A list of objects and actions in each image.\n",
    "\n",
    "Example Output:\n",
    "{\n",
    "  \"scene_story\": \"A person is cooking in the kitchen and then someone rings the doorbell.\",\n",
    "  \"images\": [\n",
    "    {\"description\": \"Someone is cooking in the kitchen.\"},\n",
    "    {\"description\": \"Someone rings the doorbell.\"}\n",
    "  ]\n",
    "}\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "# Fetch the first scene\n",
    "scene = scene_collection_time.scenes[0]\n",
    "\n",
    "# Describe the frame\n",
    "scene.describe(prompt=scene_prompt)\n",
    "\n",
    "print(scene)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### üóÇÔ∏è Describe All Scenes & Index\n",
    "---\n",
    "\n",
    "Once you are confident about your prompt. \n",
    "You can use `Frame.describe()` or `Scene.describe()` on the whole `SceneCollection` and index it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get scene from collection\n",
    "scenes = scene_collection.scenes\n",
    "\n",
    "# Describe Scenes & frames\n",
    "for scene in scenes:\n",
    "  scene.describe(prompt=scene_prompt)\n",
    "  for frame in scene.frames:\n",
    "    frame.describe(prompt=frame_prompt)\n",
    "\n",
    "# Index Scenes \n",
    "index_id = video.index_scenes(scenes=scenes, name=\"My Custom Annotations#1\")\n",
    "\n",
    "custom_scene_index = video.get_scene_index(index_id)\n",
    "print(custom_scene_index)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### üîç Search \n",
    "---\n",
    "\n",
    "> Note: it might take a additional 5-10 seconds for your index to become available for search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from videodb import IndexType\n",
    "\n",
    "# search using the index_id\n",
    "res = video.search(query=\"guns\", index_type=IndexType.scene, index_id=index_id)\n",
    "res.play()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üßë‚Äçüíª Next Steps\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "Check out the other resources and tutorials using Scene Indexing\n",
    "* If you want to bring your own scene descriptions and annotations, explore the [Custom Annotations  Pipeline](https://github.com/video-db/videodb-cookbook/blob/main/guides/video/scene-index/custom_annotations.ipynb)\n",
    "* Check out our open and flexible [Advanced Visual Search Pipelines](https://github.com/video-db/videodb-cookbook/blob/main/guides/video/scene-index/advanced_visual_search.ipynb)\n",
    "\n",
    "\n",
    "If you have any questions or feedback. Feel free to reach out to us üôåüèº\n",
    "\n",
    "* [Discord](https://colab.research.google.com/corgiredirector?site=https%3A%2F%2Fdiscord.gg%2Fpy9P639jGz)\n",
    "* [GitHub](https://github.com/video-db)\n",
    "* [VideoDB](https://colab.research.google.com/corgiredirector?site=https%3A%2F%2Fvideodb.io)\n",
    "* [Email](ashu@videodb.io)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
